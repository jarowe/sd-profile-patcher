---
phase: 02-data-pipeline-privacy
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pipeline/parsers/instagram.mjs
  - pipeline/privacy/exif-stripper.mjs
  - pipeline/privacy/gps-redactor.mjs
  - pipeline/schemas/canonical.mjs
  - pipeline/utils/logger.mjs
  - pipeline/utils/deterministic.mjs
  - package.json
autonomous: true
requirements: [PIPE-01, PIPE-06, PRIV-03, PRIV-04]

must_haves:
  truths:
    - "Instagram HTML export files are parsed into canonical node objects with caption, date, media paths, location, and tagged users"
    - "Posts missing required fields (id/date) are skipped with a warning log, never crashing the pipeline"
    - "All images processed by the pipeline have EXIF metadata stripped and GPS coordinates truncated to 2 decimal places"
    - "Post-strip verification confirms no EXIF GPS data survives in output images"
  artifacts:
    - path: "pipeline/parsers/instagram.mjs"
      provides: "Instagram HTML parser with defensive null-safe traversal"
      exports: ["parseInstagram"]
    - path: "pipeline/privacy/exif-stripper.mjs"
      provides: "EXIF stripping and post-strip verification"
      exports: ["stripExif", "verifyNoExif"]
    - path: "pipeline/privacy/gps-redactor.mjs"
      provides: "GPS truncation to 2 decimal places"
      exports: ["redactGPS"]
    - path: "pipeline/schemas/canonical.mjs"
      provides: "Canonical node schema definition matching mock-constellation.json"
      exports: ["createCanonicalNode", "NODE_TYPES", "VISIBILITY_TIERS"]
    - path: "pipeline/utils/deterministic.mjs"
      provides: "Deterministic JSON stringify with sorted keys, mulberry32 PRNG"
      exports: ["deterministicStringify", "mulberry32"]
  key_links:
    - from: "pipeline/parsers/instagram.mjs"
      to: "pipeline/schemas/canonical.mjs"
      via: "createCanonicalNode() call"
      pattern: "createCanonicalNode"
    - from: "pipeline/parsers/instagram.mjs"
      to: "pipeline/privacy/exif-stripper.mjs"
      via: "stripExif() call on each media file"
      pattern: "stripExif"
    - from: "pipeline/privacy/exif-stripper.mjs"
      to: "pipeline/privacy/gps-redactor.mjs"
      via: "redactGPS() called during node creation for location data"
      pattern: "redactGPS"
---

<objective>
Parse Instagram HTML export into canonical constellation nodes with EXIF stripping and GPS redaction.

Purpose: This is the first pipeline module -- it reads the largest data source (Instagram HTML export, 276 files) and produces normalized node objects. It also establishes the shared canonical schema, privacy utilities (EXIF stripping, GPS redaction), and deterministic output helpers that Plan 02 (Carbonmade) will reuse.

Output: `pipeline/parsers/instagram.mjs`, `pipeline/privacy/exif-stripper.mjs`, `pipeline/privacy/gps-redactor.mjs`, `pipeline/schemas/canonical.mjs`, `pipeline/utils/logger.mjs`, `pipeline/utils/deterministic.mjs`
</objective>

<execution_context>
@C:\Users\rowej\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\rowej\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-data-pipeline-privacy/02-CONTEXT.md
@.planning/phases/02-data-pipeline-privacy/02-RESEARCH.md
@src/constellation/data/mock-constellation.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Shared pipeline foundation -- canonical schema, privacy utilities, deterministic helpers</name>
  <files>
    pipeline/schemas/canonical.mjs
    pipeline/privacy/exif-stripper.mjs
    pipeline/privacy/gps-redactor.mjs
    pipeline/utils/logger.mjs
    pipeline/utils/deterministic.mjs
    package.json
  </files>
  <action>
    Install dev dependencies: `npm install -D cheerio sharp exifr glob ajv date-fns`

    Create `pipeline/schemas/canonical.mjs`:
    - Define NODE_TYPES: milestone, person, moment, idea, project, place (matching mock-constellation.json types)
    - Define VISIBILITY_TIERS: public, friends, private (per user decision -- EXACTLY 3 tiers, NOT 4).
      IMPORTANT CLARIFICATION: The ROADMAP success criteria #2 mentions "public/private/redacted/friends" -- "redacted" is NOT a 4th visibility tier. It refers to the privacy TRANSFORMATION applied to public-tier nodes (GPS truncated to 2 decimals, EXIF stripped, non-allowlisted names replaced with generic labels). The canonical schema stores only 3 visibility values: "public", "friends", "private". The redaction transformations are applied by the privacy pipeline (exif-stripper, gps-redactor, visibility.mjs allowlist enforcement) to nodes BEFORE they reach the output -- they do not appear as a tier in the data model.
    - Export `createCanonicalNode(fields)` factory function that validates required fields (id, date) and fills optional fields with safe defaults. Returns object matching mock-constellation.json node shape: { id, type, title, date, epoch, description, media, connections, size, isHub, source, sourceId, visibility, entities: { people, places, tags, clients, projects }, location }
    - If required field `id` or `date` is missing, return null (caller logs warning and skips)
    - All arrays default to [] and strings to "" for safe rendering

    Create `pipeline/privacy/exif-stripper.mjs`:
    - Export `stripExif(inputPath, outputPath)`: uses sharp to process image (default settings strip ALL metadata). Write to outputPath.
    - Export `verifyNoExif(filePath)`: uses exifr.parse() with { gps: true, tiff: true, xmp: true, iptc: true, icc: false } to check for GPS metadata. Returns { clean: boolean, violations: string[] }. If GPS data found, returns clean=false with description.
    - Export `stripAndVerify(inputPath, outputPath)`: convenience that calls strip then verify, throws Error if verification fails (fail-closed per user decision).
    - Handle missing/unreadable files gracefully (log warning, skip, do not crash).

    Create `pipeline/privacy/gps-redactor.mjs`:
    - Export `redactGPS(lat, lng, visibility, isMinor)`:
      - If isMinor: return null (no GPS at all per PRIV-05)
      - If visibility === 'private': return null
      - If lat/lng are null/undefined: return null
      - Otherwise: return { lat: Number(Number(lat).toFixed(2)), lng: Number(Number(lng).toFixed(2)) }
    - This handles the floating point precision pitfall (Number wrapping toFixed).

    Create `pipeline/utils/logger.mjs`:
    - Export a simple logger with levels: info, warn, error
    - Format: `[pipeline:{module}] {level}: {message}`
    - Warnings are counted and summary printed at end
    - Errors cause pipeline to exit with code 1

    Create `pipeline/utils/deterministic.mjs`:
    - Export `deterministicStringify(data)`: JSON.stringify with sorted object keys replacer, 2-space indent. Per RESEARCH.md pattern.
    - Export `mulberry32(seed)`: Copy from existing `src/constellation/layout/helixLayout.js` (reuse, don't reinvent). Returns a function that produces values in [0, 1).
    - Export `sortedGlob(pattern, options)`: wraps glob() and sorts results alphabetically for cross-platform determinism.
  </action>
  <verify>
    Run `node -e "import('./pipeline/schemas/canonical.mjs').then(m => console.log(Object.keys(m)))"` -- should print exports.
    Run `node -e "import('./pipeline/privacy/gps-redactor.mjs').then(m => { const r = m.redactGPS(28.538472, -81.379234, 'public', false); console.log(r); })"` -- should print `{ lat: 28.54, lng: -81.38 }`.
    Run `node -e "import('./pipeline/utils/deterministic.mjs').then(m => console.log(m.deterministicStringify({b:2,a:1})))"` -- should print keys sorted (a before b).
    `npm ls cheerio sharp exifr glob ajv date-fns` -- all installed as devDependencies.
  </verify>
  <done>
    Canonical schema factory creates valid node objects matching mock-constellation.json shape with EXACTLY 3 visibility tiers (public/friends/private). EXIF stripper uses sharp+exifr. GPS redactor truncates to 2 decimals with minors/private null handling. Logger, deterministic stringify, and mulberry32 PRNG all export correctly. All 6 new devDependencies installed.
  </done>
</task>

<task type="auto">
  <name>Task 2: Instagram HTML parser -- discovery, basic parsing, normalization, and dedup</name>
  <files>
    pipeline/parsers/instagram.mjs
  </files>
  <action>
    Create `pipeline/parsers/instagram.mjs`:

    CRITICAL: Instagram export format is HTML ("Download Your Information", HTML version). The exact DOM structure is not known until the actual export is examined. The parser MUST include a discovery phase.

    Export `parseInstagram(exportDir, options)`:

    **Part A -- Discovery and basic parsing:**

    1. **Discovery step**: Load the first HTML file found in `{exportDir}/content/` using cheerio. Log the top-level structure (tag names, class names, first 3 elements) to help debug selector issues. This runs once per pipeline invocation.

    2. **File discovery**: Use sortedGlob to find all `*.html` files in `{exportDir}/content/` (posts_1.html, posts_2.html, etc. and reels.html, stories.html). Also discover media files in `{exportDir}/media/`.

    3. **Post parsing**: For each HTML file, load with cheerio and extract post elements. Instagram HTML exports typically use simple div structures. The parser should try multiple selector strategies:
       - Look for `<div>` elements that contain both text content and `<img>` or `<video>` tags
       - Look for timestamp elements (`<time>`, elements with datetime attributes, or date-like text patterns)
       - Look for location tags (elements with location-related class names or text patterns)

    4. **Per-post extraction** (defensive, never crashes):
       - `caption`: Text content from post body. Default: ""
       - `dateText`: From <time> element datetime attr, or parse date-like text. REQUIRED -- skip post if unparseable.
       - `media`: Array of relative image/video paths from <img src> / <video src>. Resolve relative to exportDir.
       - `locationText`: From location element if present. Default: null
       - `taggedUsers`: From any tagged/mentioned user elements. Default: []
       - Wrap each post extraction in try/catch. On error, log warning with post index, continue to next.

    **Part B -- Normalization and dedup:**

    5. **Normalization**: For each successfully parsed post, call `createCanonicalNode()` with:
       - `id`: "ig-{incrementalIndex}" (zero-padded 3 digits, e.g., "ig-001")
       - `type`: "moment" (Instagram posts are life moments)
       - `title`: First 60 chars of caption or "Instagram Post {date}"
       - `date`: Parsed to ISO format "YYYY-MM-DD" using date-fns parse()
       - `epoch`: Determined by date ranges (configurable, default same as mock: Early Years 2001-2010, College 2010-2014, Career Start 2014-2018, Growth 2018-2022, Present 2022-2026)
       - `description`: Full caption text
       - `media`: Array of original media paths (EXIF stripping happens later in pipeline)
       - `source`: "instagram"
       - `sourceId`: Derived from filename or content hash for dedup (within-source only per user decision)
       - `visibility`: "private" by default (allowlist promotes to public/friends)
       - `entities.people`: taggedUsers array
       - `entities.places`: [locationText] if present
       - `entities.tags`: Extract hashtags from caption using regex /#(\w+)/g

    6. **Deduplication**: Within-source only (per user decision). Deduplicate by sourceId. If duplicate found, keep first occurrence, log warning.

    7. **Summary**: Log count of parsed posts, skipped posts, and any unknown HTML elements encountered. Return { nodes: CanonicalNode[], stats: { total, parsed, skipped, warnings } }.

    8. **Resilience**: If the entire exportDir is missing or empty, return { nodes: [], stats: { total: 0, parsed: 0, skipped: 0, warnings: ['Instagram export directory not found'] } }. Never crash the pipeline.

    IMPORTANT: The parser will almost certainly need selector adjustments once the actual Instagram export is available. Build it to be easily tweakable -- keep selectors in a config object at the top of the file. Log selectors used and match rates.
  </action>
  <verify>
    Run `node -e "import('./pipeline/parsers/instagram.mjs').then(m => console.log(typeof m.parseInstagram))"` -- should print "function".
    Since actual Instagram export may not be available yet, verify graceful handling: `node -e "import('./pipeline/parsers/instagram.mjs').then(m => m.parseInstagram('./nonexistent').then(r => console.log(r.stats)))"` -- should print stats with warning about missing directory, not crash.
    If Instagram export IS available at `data-private/instagram/`, run `node -e "import('./pipeline/parsers/instagram.mjs').then(m => m.parseInstagram('./data-private/instagram').then(r => console.log(r.stats)))"` and verify nodes are produced.
  </verify>
  <done>
    Instagram parser reads HTML export files, extracts posts with defensive null-safe traversal, normalizes to canonical schema, deduplicates within-source, and returns array of canonical nodes. Missing/malformed posts are skipped with warnings. Missing export directory returns empty array gracefully. Selector strategy is configurable. Stats are logged.
  </done>
</task>

</tasks>

<verification>
- `node -e "import('./pipeline/schemas/canonical.mjs')"` loads without error
- `node -e "import('./pipeline/parsers/instagram.mjs')"` loads without error
- `node -e "import('./pipeline/privacy/exif-stripper.mjs')"` loads without error
- `node -e "import('./pipeline/privacy/gps-redactor.mjs')"` loads without error
- GPS redaction produces exactly 2 decimal places: `28.538472` -> `28.54`
- Missing Instagram dir returns empty nodes array, not crash
- All imports use ESM (import/export, .mjs extension)
</verification>

<success_criteria>
Instagram parser exists and handles HTML exports defensively. Canonical schema factory produces nodes matching mock-constellation.json shape with exactly 3 visibility tiers (public/friends/private -- "redacted" is a transformation, not a tier). EXIF stripper chains sharp+exifr for belt-and-suspenders verification. GPS redactor truncates to city-level. All utilities are deterministic and reusable by Plan 02.
</success_criteria>

<output>
After completion, create `.planning/phases/02-data-pipeline-privacy/02-01-SUMMARY.md`
</output>
